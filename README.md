# Learnathon_BFSI

Here is a **detailed and professional README.md file** for your project titled:

---

# ğŸš— AI-Powered Fraud Detection in Auto Insurance

### ğŸ§  Predictive Modeling for Smarter Claims Management

---

## ğŸ“Œ Problem Statement

Insurance fraud in the auto sector leads to billions in losses every year, resulting in higher premiums for customers and significant financial strain on insurance companies. The goal of this project is to leverage AI/ML techniques to build a robust **fraud detection system** that can accurately flag potentially fraudulent claims using structured historical insurance claim data.

This solution helps insurers:

* Automate fraud detection in real-time.
* Prioritize claims that require deeper investigation.
* Enhance the efficiency of the claims management pipeline.

---

## ğŸ“Š Dataset Description

The dataset contains **structured claim records** with 50+ features ranging from policy details, customer demographics, accident specifics, and financial information.

ğŸ“ Data Dictionary Highlights:

* `Claim_ID`: Unique claim identifier
* `Customer_Life_Value1`: Estimated value of customer
* `Age_Insured`, `Gender`, `Education`, `Occupation`, etc.
* `Accident_Date`, `Accident_Severity`, `Accident_Type`
* `Annual_Mileage`, `DiffIN_Mileage`, `Low_Mileage_Discount`
* `Total_Claim`, `Injury_Claim`, `Property_Claim`, `Vehicle_Claim`
* `Fraud_Ind`: **Target column** (Y/N)

For full schema, see [`data_dictionary.txt`](./data_dictionary.txt)

---

## âš™ï¸ Features of the Solution

* âœ… **Duplicate detection & removal**
* ğŸ§© **Missing value identification & imputation**
* ğŸš¨ **Outlier detection using Z-Score and IQR methods**
* ğŸ§  **Feature encoding & scaling**
* ğŸ” **Data imbalance handling** using SMOTE
* âš’ï¸ **Model training with 10 ML classifiers**
* ğŸ“ˆ **Evaluation using accuracy, precision, recall, F1, ROC-AUC**
* ğŸ† **Model comparison & leaderboard visualization**
* ğŸ¯ Final fraud prediction on unseen claims

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ auto_insurance.csv
â”‚   â””â”€â”€ data_dictionary.txt
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ saved_model.pkl
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª Algorithms Used

We evaluated 10 models:

| Model               | Accuracy | Precision | Recall | ROC-AUC |
| ------------------- | -------- | --------- | ------ | ------- |
| Logistic Regression | âœ…        | âœ…         | âœ…      | âœ…       |
| Decision Tree       | âœ…        | âœ…         | âœ…      | âœ…       |
| Random Forest       | âœ…        | âœ…         | âœ…      | âœ…       |
| Gradient Boosting   | âœ…        | âœ…         | âœ…      | âœ…       |
| AdaBoost            | âœ…        | âœ…         | âœ…      | âœ…       |
| KNN                 | âœ…        | âœ…         | âœ…      | âœ…       |
| SVM                 | âœ…        | âœ…         | âœ…      | âœ…       |
| Naive Bayes         | âœ…        | âœ…         | âœ…      | âœ…       |
| Extra Trees         | âœ…        | âœ…         | âœ…      | âœ…       |
| Bagging Classifier  | âœ…        | âœ…         | âœ…      | âœ…       |

> âœ… Final model: **Random Forest** + **SMOTE** for best F1 & recall.

---

## ğŸ§  How It Works (Pipeline Overview)

```python
1. Load dataset
2. Drop duplicates
3. Handle missing values (mode, mean, or forward fill)
4. Encode categorical features (Label/One-Hot Encoding)
5. Outlier detection (Z-Score method)
6. Feature scaling (StandardScaler)
7. Train/Test Split
8. Handle class imbalance (SMOTE)
9. Train 10 classification models
10. Evaluate and compare metrics
11. Save best model
```

---

## ğŸ“Œ Results & Insights

* Features like `DiffIN_Mileage`, `Low_Mileage_Discount`, `Accident_Hour`, and `Capital_Gains/Loss` showed strong correlation with fraudulent behavior.
* Data imbalance was significantly handled using **SMOTE**, improving recall by \~15%.
* **Random Forest** showed the best performance with high F1-score and low false positives.

---

## ğŸ›  Installation & Usage

```bash
git clone https://github.com/your-username/auto-insurance-fraud-detection.git
cd auto-insurance-fraud-detection
pip install -r requirements.txt
```

Run the pipeline:

```bash
python src/model.py
```

For detailed data exploration:

```bash
jupyter notebook notebooks/exploratory_analysis.ipynb
```

---

## ğŸ“¦ Requirements

```txt
pandas
numpy
matplotlib
seaborn
scikit-learn
imbalanced-learn
xgboost
```

---

## ğŸ“Œ Future Enhancements

* âœ… Deploy as Streamlit dashboard
* ğŸ” Use deep learning (LSTM/AutoEncoders) for sequential claim fraud
* ğŸ“‰ Time-series fraud trend visualization
* ğŸ›° Integration with real-time claim submission system

---

## ğŸ“œ License

This project is open-sourced under the [MIT License](LICENSE).

---

## ğŸ‘¨â€ğŸ’» Developed By

* **Abhisek Panda** â€“ [GitHub](https://github.com/abhisek2004)
* Team: *  *
